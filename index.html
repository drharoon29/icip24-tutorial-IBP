<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Imagining Beyond Pixels - ICIP 2024 Tutorial</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Imagining Beyond Pixels: Bridging Modalities for Multimodal Representation and Learning</h1>
        <p><strong>Tutorial </strong> @ IEEE International Conference on Image Processing (ICIP'24) </p>
        <p><strong>Date:</strong> 27th October 2024</p>
        <p><strong>Location:</strong> Abu Dhabi National Exhibition and Convention Centre, Abu Dhabi</p>
    </header>

    <nav>
        <ul>
            <li><a href="#about">About</a></li>
            <li><a href="#contents">Contents</a></li>
            <li><a href="#organizers">Organizers</a></li>
            <li><a href="#contact">Contact</a></li>
        </ul>
    </nav>

<div class="image-container">
        <img src="swarm_logo.png" alt="Description" style="width: 200px; height: 200px;">
        <img src="uet.png" alt="Image 1">
        <img src="icip.png" alt="Description" style="width: 200px; height: 100px;"">

    </div>

    <section id="about">
        <h2>About</h2>
        <p>Our perception of the environment is multimodal, encompassing visual observations, auditory stimuli, tactile receptors, aromatic sensations, and more. Modality denotes the way the world is perceived and encountered. In the perspective of machine learning, modality pertains to the specific category of data that a model is capable of handling, such as audio, images, or text. Each modality possesses distinct characteristics and attributes, necessitating varied processing and analytical approaches to extract valuable information. Multimodal Representation and Learning processes and analyze data from multiple sources or modalities simultaneously, such as video, audio, and sensor signal. This approach quite resembles to the natural phenomenon and is essential for handling the heterogeneity and complexity of real-world data, thus been applied to various applications, including sentiment analysis, natural language processing, and computer vision. In machine learning, Multi-modal learning is a paradigm focused on combining multiple modalities of data such as audio-image, image-text learning to improve the performance of a model. The idea behind multimodal learning is that different modalities can provide complementary cues that can help a model make more accurate predictions or decisions. For example, a model that can process both images and text can better understand the context of image and make accurate predictions.
Recognizing the significance of multimodal representation and learning, this tutorial has been crafted to familiarize participants with cutting-edge research trends, applications, and hands-on experiences in multimodal representation and learning. It delivers a comprehensive introduction to multimodal representation and learning and emphasizing practical aspects. Furthermore, the tutorial explores applications and research challenges that participants can engage with and address throughout the course.
</p>
        <p>By the end of this tutorial, the audience will be able to:</p>
        <ul>
            <li>Demonstrate basic concepts and rationale about multimodal learning – its functionality, applications, and challenges.</li>
            <li>Understand different applications and state-of-the-art research in the domain of multimodality.</li>
            <li>Explore applications to carry out research in multimodal fusion, face-voice association, and image-text joint representation learning.</li>
            <li>Grab theoretical knowledge and practical aspects of various challenges (Feature Fusion, Missing Modalities, trustworthy AI, etc.).</li>
        </ul>
    </section>

    <section id="contents">
        <h2>Contents</h2>
        <h3>Multimodal Representation and Learning </h3>
        <ul>
            <li>Introduction and Motivation</li>
            <li>Why Multimodal Learning?</li>
            <li>Real-world Environment is Multimodal</li>
            <li>Unimodal vs Multimodal Learning</li>
            <li>Leveraging Unimodal Networks for Multimodal Learning</li>
            <li>Applications</li>
            <li>Methods and Models: Application Specific Emergence</li>
            <li>Fusion Strategies</li>
        </ul>

        <h3>Bridging Audio-Visual Modalities </h3>
        <ul>
            <li>Applications</li>
            <li>Methods: Face-Voice Association, Audio-Visual Speech Recognition, Latent Properties on Identity Verification</li>
            <li>Datasets and Challenges: Vox-Celeb, MAV-Celeb Dataset, and Pipeline.</li>
        </ul>

        <h3>Bridging Image-Text Modalities </h3>
        <ul>
            <li>Applications</li>
            <li>Methods: Image-Text Classification / Retrieval, Sentiment Analysis</li>
            <li>Datasets and Challenges</li>
        </ul>

        <h3>Technical Challenges and Latest Research Trends </h3>
        <ul>
            <li>Feature Fusion</li>
            <li>Representation and Alignment</li>
            <li>Reasoning and Generation</li>
            <li>Multi-Modality Scenario and Missing Modality</li>
            <li>Ethical and Trustworthy AI Perspective</li>
        </ul>
    </section>

    <section id="organizers">
        <h2>Organizers</h2>

<div class="organizers-container">
        <div class="organizer">
            <img src="haroon.jpg" alt="Organizer 1">
            <div class="bio">
                <h3>Prof. Muhammad Haroon Yousaf</h3>
                <p>Muhammad Haroon Yousaf is working as a Professor/Chairman of Computer Engineering at University of Engineering and Technology Taxila, Pakistan. He has more than 19 years of teaching/research experience. His research interests are Image Processing, Computer Vision, and Robotics. He is also the Director of Swarm Robotics Lab under National Centre of Robotics and Automation Pakistan. He has published more than 100 papers in International SCI-Indexed Journals/Conferences. He has secured many funded (Govt. & Industry) research projects in his areas of interest. Prof. Haroon has received the BEST UNIVERSITY TEACHER AWARD by HIGHER EDUCATION COMMISSION, PAKISTAN in 2014. He is a Senior Member of IEEE and SPS. He is also serving as Associate Editor of IEEE Transactions on Circuits and Systems on Video Technology (TCSVT). He is also appointed as Professor Extraordinarius at University of South Africa since February 2023. He has also delivered a short course and a tutorial at ICIP 2023. He has presented his research as Keynote/Invited Speakers at many conferences/workshops. Detailed profile is available at https://fms.uettaxila.edu.pk/Profile/haroon.yousaf#.</p>
            </div>
        </div>

        <div class="organizer">
            <img src="saad.jpg" alt="Organizer 2">
            <div class="bio">
                <h3>Muhammad Saad Saaed</h3>
                <p>Muhammad Saad Saeed is working as a Research Associate in Swarm Robotics Lab under National Centre of Robotics and Automation Pakistan. He is also working as Chief Technology Officer (CTO) in a Computer Vision based startup “BeeMantis”. Saad has more than four years of R&D experience in Deep Learning with applications in Computer Vision, Multimodal Learning, AI-on-the-Edge, Speech, and Audio Processing. He is a Member of IEEE and SPS. He has also delivered a short course at IEEE ICIP 2023.</p>
            </div>
        </div>

        <div class="organizer">
            <img src="shahnawaz.jpg" alt="Organizer 2">
            <div class="bio">
                <h3>Dr. Shah Nawaz</h3>
                <p>Shah Nawaz is currently serving as an Assistant Professor at Johannes Kepler University Linz - JKU Austria. He did his PhD from University of Insubria, Italy. Before joining JKU, Shah Nawaz was a researcher at IMEC Belgium with focus on computer vision and deep learning. Earlier he was the Postdoc at DESY Germany and IIT Genova, Italy. He has developed various techniques in the doctoral and postdoctoral program to learn presentation of various multimodal applications ranging from classification to cross-modal retrieval.</p>
            </div>
        </div>
    </div>


    </section>

    <section id="contact">
        <h2>Contact</h2>
        <p>If you have any questions or need further information, please contact:</p>
        <p><strong>Prof. Muhammad Haroon Yousaf</strong></p>
        <p>Email: <a href="mailto:haroon.yousaf@uettaxila.edu.pk">haroon.yousaf@uettaxila.edu.pk</a> <a href="mailto:haroon.yousaf@ieee.org">haroon.yousaf@ieee.org</a></p>
    </section>

    <footer>
        <p>&copy; 2024 Imagining Beyond Pixels | ICIP 2024</p>
    </footer>
</body>
</html>
